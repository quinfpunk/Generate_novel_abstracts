{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the data you want to study\n",
    "\n",
    "You can extract 1 to multiple years of papers with all their references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_directory containing the batch files\n",
    "files_directory = \"../data/dblp_batched_processed\"\n",
    "\n",
    "# Find all batch files\n",
    "batch_files = glob.glob(os.path.join(files_directory, \"processed_papers_batch_*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Filter & extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract batch number and sort files numerically\n",
    "def extract_batch_number(filename):\n",
    "    match = re.search(r'papers_batch_(\\d+)\\.csv', os.path.basename(filename))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49 batch files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch files:   0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch files: 100%|██████████| 49/49 [01:03<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete!\n",
      "Total papers from 2020: 18213\n",
      "2020 papers saved to: ../data/dblp_papers_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# Sort the batch files by their numerical batch number\n",
    "batch_files.sort(key=extract_batch_number)\n",
    "\n",
    "print(f\"Found {len(batch_files)} batch files to process\")\n",
    "\n",
    "# Initialize empty list to store 2020 papers dataframes (more efficient than concat in loop)\n",
    "dfs_filtered = []\n",
    "\n",
    "# Process each batch file in numerical order with progress bar\n",
    "for batch_file in tqdm(batch_files, desc=\"Processing batch files\"):\n",
    "    batch_number = extract_batch_number(batch_file)\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file - only read necessary columns to save memory\n",
    "        data = pd.read_csv(\n",
    "            batch_file, \n",
    "            sep=';',\n",
    "            usecols=lambda x: x in ['id', 'title', 'year', 'references', 'abstract']\n",
    "        )\n",
    "\n",
    "        if 'year' in data.columns:\n",
    "            year_filtered_papers = data[data['year'].isin(years)].copy()\n",
    "            if not year_filtered_papers.empty:\n",
    "                year_filtered_papers['references'] = year_filtered_papers['references'].apply(ast.literal_eval)\n",
    "                dfs_filtered.append(year_filtered_papers)\n",
    "                \n",
    "        # Clean up to free memory\n",
    "        del data\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error retrieving batch #{batch_number}: {e}\")\n",
    "\n",
    "# Combine all 2020 papers at once (more efficient than concat in loop)\n",
    "if len(dfs_filtered)>0:\n",
    "    # Concatenate all dataframes in the list into a single dataframe\n",
    "    df_filtered = pd.concat(dfs_filtered, ignore_index=True)\n",
    "    \n",
    "    # Save the combined 2020 papers dataframe\n",
    "    df_filtered_output = os.path.join(output_directory, \"dblp_papers_filtered.csv\")\n",
    "    df_filtered.to_csv(df_filtered_output, index=False, sep=';')\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total papers from {\",\".join([str(year) for year in years])}: {len(df_filtered)}\")\n",
    "    print(f\"{\",\".join([str(year) for year in years])} papers saved to: {df_filtered_output}\")\n",
    "else:\n",
    "    print(f\"\\nNo papers from {\",\".join([str(year) for year in years])}  found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of outCitations: 13.466974139351013\n"
     ]
    }
   ],
   "source": [
    "avg_out_len = df_filtered['references'].apply(len).mean()\n",
    "\n",
    "print(\"Average length of outCitations:\", avg_out_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. (Optional) Filter the data depending by a threshold percentage of refence papers that are actually available in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 1  # Set your desired threshold\n",
    "# all_ids = data['id'].unique()\n",
    "\n",
    "# def fraction_in_combined(cites):\n",
    "#     if len(cites) == 0:\n",
    "#         return True\n",
    "#     match_count = sum(int(cid) in all_ids for cid in cites)\n",
    "#     return (match_count / len(cites)) >= threshold\n",
    "\n",
    "# df_filtered_filtered = df_filtered[df_filtered['references'].apply(fraction_in_combined)].copy(deep=True)\n",
    "# print(len(df_filtered_filtered))\n",
    "# avg_out_len = df_filtered_filtered['references'].apply(len).mean()\n",
    "\n",
    "# print(\"Average length of outCitations:\", avg_out_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. (Optional) Only get random sample of filtered data for fastest processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of outCitations: 14.75\n"
     ]
    }
   ],
   "source": [
    "if sampling:\n",
    "    sub_df_filtered = df_filtered.sample(n=100, random_state=42)\n",
    "    out_cited_ids = np.unique(np.concatenate(sub_df_filtered['references'].values))\n",
    "    avg_out_len = sub_df_filtered['references'].apply(len).mean()\n",
    "    print(\"Average length of outCitations:\", avg_out_len)\n",
    "    df_filtered_with_refs_list = [sub_df_filtered]\n",
    "else:\n",
    "    df_filtered_with_refs_list = [df_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Get all references of filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected total number of papers: 1564\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected total number of papers:\", len(sub_df_filtered)+len(out_cited_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch files: 100%|██████████| 49/49 [01:01<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete!\n",
      "Sample 100 papers from 2020 with Reference papers: 1564 papers in total\n",
      "Saved to: ../data/dblp_papers_filtered_sample_with_refs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list to store 2020 papers dataframes (more efficient than concat in loop)\n",
    "df_filtered_with_refs_list = [sub_df_filtered]\n",
    "\n",
    "# Extract batch number and sort files numerically\n",
    "def extract_batch_number(filename):\n",
    "    match = re.search(r'processed_papers_batch_(\\d+)\\.csv', os.path.basename(filename))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0\n",
    "\n",
    "# Sort the batch files by their numerical batch number\n",
    "batch_files.sort(key=extract_batch_number)\n",
    "# Process each batch file in numerical order with progress bar\n",
    "for batch_file in tqdm(batch_files, desc=\"Processing batch files\"):\n",
    "    batch_number = extract_batch_number(batch_file)\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file - only read necessary columns to save memory\n",
    "        data = pd.read_csv(\n",
    "            batch_file, \n",
    "            sep=';',\n",
    "            usecols=lambda x: x in ['id', 'title', 'year', 'references', 'abstract']\n",
    "        )\n",
    "        \n",
    "        # Filter papers from 2020 and collect in list\n",
    "        if 'id' in data.columns:\n",
    "            ref_data = data[data['id'].isin(out_cited_ids)].copy()\n",
    "            if not ref_data.empty:\n",
    "                ref_data['references'] = ref_data['references'].apply(lambda x: [])\n",
    "                df_filtered_with_refs_list.append(ref_data)\n",
    "                \n",
    "        # Clean up to free memory\n",
    "        del data\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error processing batch #{batch_number}: {e}\")\n",
    "        \n",
    "if len(df_filtered_with_refs_list)>0:\n",
    "    df_filtered_with_refs = pd.concat(df_filtered_with_refs_list, ignore_index=True)\n",
    "    \n",
    "    # Save the combined 2020 papers dataframe\n",
    "    df_filtered_with_refs_output = os.path.join(output_directory, \"dblp_papers_filtered_sample_with_refs.csv\")\n",
    "    df_filtered_with_refs.to_csv(df_filtered_with_refs_output, index=False, sep=';')\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Sample {len(df_filtered_with_refs_list[0])} papers from {\"\".join([str(year) for year in years])} with Reference papers: {len(df_filtered_with_refs)} papers in total\")\n",
    "    print(f\"Saved to: {df_filtered_with_refs_output}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 612177,
     "sourceId": 11503307,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
